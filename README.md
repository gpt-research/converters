
# @gpt-research/converters
**üöÄ Welcome to GPT Research Converters!**

Converters offers a suite of APIs and tools designed to streamline the process of downloading and training state-of-the-art pretrained models. By harnessing the power of pretrained models, you can significantly lower your compute costs, reduce your carbon footprint, and save valuable time and resources that would otherwise be spent on training models from scratch.

## Ethos and Mission

üöÄ **Blazing Trails in AI Democratization!**

At GPT Research, we set the AI world ablaze with the launch of [@gpt-research/hub](https://github.com/gpt-research/hub). This platform illuminated the way, offering a haven for state-of-the-art AI models. But you, the community, hungered for more than mere downloads. You craved usability without barriers. No more academic walls!

üõ†Ô∏è **Converters: Unleashing the Power of AI for All!**

Enter Converters! It's the key to unlock the full potential. From obtaining models to deploying them, we've streamlined the journey. No technical wizardry needed! We've bundled everything you need to download, load, and utilize these models seamlessly. And that's not all! We've even crafted ready-to-use pipelines for common tasks.

üí• **Join the Revolution!**

Our mission is clear - we're here to shatter boundaries. With Converters, AI isn't just for the elite. It's for everyone! Let's redefine the possibilities and shape the future together. Embrace the AI revolution! üåü

## Features

‚ú® **Effortless Model Retrieval**: Seamlessly download pretrained models from [The Hub](https://github.com/gpt-research/hub) with just a few simple packages.

üèÉ‚Äç‚ôÇÔ∏è **Runs in JS/TS/Node/Deno/Browser**: Converters is compatible with JavaScript and TypeScript, making it versatile for various environments.

üåê **Wide Range of Model Support**: Access a diverse selection of pretrained models to suit various tasks and domains.

‚ö° **Optimized for Efficiency**: Converters is designed to maximize efficiency, ensuring you get the most out of your resources.

## Getting Started

To begin using Converters, checkout this guide that showcases our `TextGenerationPipeline` pipeline.
1. **Import Converters Library**:

   If you're using JavaScript or TypeScript:

   ```javascript
   import { TextGenerationPipeline } from 'https://esm.sh/gh/gpt-research/converters/src/converters.js';
   ```

   If you're working with HTML and JavaScript, add the following script tag to your HTML file:

   ```html
   <script type="module">
     import { TextGenerationPipeline } from 'https://esm.sh/gh/gpt-research/converters/src/converters.js';
   </script>
   ```

   This imports the `TextGenerationPipeline` from Converters, allowing you to access the text generation capabilities.

2. **Initialize the Pipeline**:

   Use the `TextGenerationPipeline` function to initialize the pipeline with the desired model. Refer to the Pipelines for detailed information on parameters and returns.

3. **Generate Text**:

   Once the pipeline is initialized, you can use it to generate text by providing a prompt. Refer to the Pipelines for detailed information on parameters and returns.

4. **Utilize the Generated Text**:

   You can log or further process the generated text as per your application's requirements.

Please ensure you have an active internet connection to fetch the necessary libraries. If you encounter any issues, refer to the installation and usage guides in the documentation.

For more advanced usage and options, consult the API documentation and examples provided. Happy generating! üöÄ


## Pipelines

### Why Pipelines?

- üîç **Efficient Model Retrieval**: Models are automatically downloaded and cached from the gpt-research Hub, reducing the need for manual setup and saving valuable development time.

- üìä **Automated Tokenization**: The pipeline manages tokenization, a crucial step in processing text data for the model, ensuring accurate and efficient generation.

- ‚öôÔ∏è **Compute and Model Handling**: The pipeline efficiently handles the computational resources required for model inference, optimizing performance and minimizing resource consumption.

- üöÄ **Blazing Fast Inference Engine**: Our specially optimized inference engine operates in the background, allowing for swift and responsive text generation.

###  TextGenerationPipeline
The `TextGenerationPipeline` is a powerful tool that streamlines the process of generating text using pretrained models. It handles a range of technical complexities behind the scenes, ensuring a seamless experience for developers.

## Technical Benefits



#### Import
```typescript 
import { TextGenerationPipeline } from 'converters'
```
#### Initialization
```typescript
const pipeline = await TextGenerationPipeline(modelName: string);
```
##### Parameters

| Name       | Type     | Description                                        |
|------------|----------|----------------------------------------------------|
| `modelName`| `string` | Name of the pretrained model from the hub to use for generation. |

##### Returns
A `Promise` that resolves to a `TextGenerationPipeline` instance.

#### Generating Text

```typescript
const generatedText = pipeline(prompt: string);
```

##### Parameters

| Name    | Type     | Description                    |
|---------|----------|--------------------------------|
| `prompt`| `string` | The input prompt for generation.|

##### Returns
A `string` containing the generated text.

## Example

```typescript
import { TextGenerationPipeline } from 'converters';

const main = async () => {
  // Initialize the pipeline with the desired model
  const pipeline = await TextGenerationPipeline("@gpt-research/CamelGPT-mini");

  // Generate text using the pipeline
  const generatedText = pipeline("Write a poem about camels.");

  // Log or use the generated text
  console.log(generatedText);
};

main();
```
In the above example, we demonstrate how to generate text using the `CamelGPT-mini` model
## Contributing

We welcome contributions from the community! Whether you're reporting bugs, suggesting enhancements, or submitting pull requests, your input helps make Converters even more powerful.

For more information, refer to our [contribution guidelines](./CONTRIBUTING.md).

## License

This project is licensed under the [MIT License](./LICENSE).

## Support

If you have any questions, issues, or need further assistance, please don't hesitate to reach out on our [GitHub repository](https://github.com/gpt-research/converters).

---

Thank you for choosing GPT Research Converters. Let's revolutionize the way we approach pretrained models together! üåü